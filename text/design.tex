In this section, we propose our design of probabilistic skyline evaluation using kd-tree upon MapReduce environment.

The general idea is that we evenly split the whole instances to several subsets put into several machines, and let every machine compute the equation 3 of every instance. After instances' probabilistic skyline results are obtained, the intermediate results are merged in a machine to compute the final object probabilistic skyline answer through Equation 4.

There are three major considerations that affect the performance of computation.

\begin{enumerate}
  \item The cost suffered from Shuffling data from Map to Reduce.
  \item The cost of figuring out the Pskyline answer of all instances in the reduce phase.
  \item The cost of merging all intermediate results to answer final object Pskyline value.
\end{enumerate}

\subsection{Paralleling using kd-Tree}
our task is to build a balanced k-d tree~\cite{kd} of N points to m machines. For simplicity and convenience of presentation, N and m are assumed to be powers of two. Before presenting the construction of distributed kd-tree, we introduce the definition of a k-d tree.

Consider a set of k-dimensional points. A k-d tree is a binary tree upon the points. The root of it is the original set of points, and the subtrees are root's children. The construction of k-d tree starts with choosing one of the k dimensions, finding the median of the points. The median along the dimension generates a splitting hyperplane that divides the set of points into two equal sized sets. The two sets are put into the left and right subtree (child) of the root respectively. The construction recursively generates the subtrees by finding the new medians of two subsets along another dimension, splitting the hyperplane along the dimension, until each leaf corresponds to only one point.

We are able to observe that the number of points in every subtree upon the same level is (approximately) the same, since the parent always generates children by splitting median. It gives us the incentive to compute instances' probabilistic skyline results using MapReduce.

Recall that we have m machines and m is powers of two. We partially constructed k-d tree in which nodes and leaves are within $log$\hspace{0.03 in}$m$ levels. Let the preprocessing step launch a master node to construct k-d tree within $log$\hspace{0.03 in}$m$ levels. A small variation is made for the k-d tree: points are only stored in leaves. Nodes other than leaves are only a hyper-rectangle. After that, every leaf in the k-d tree is composed of N/m points, and bounded by a k-dimensional hyper-rectangle. The frontiers of the rectangle is delimited, and is going to be one key in the Map phase later. We store the frontier information of m leaves into DFS (Distributed File System).
%The modification can be designed by sliding split hyperplane from original place to guarantee no points is cut-off by splitting~\cite{maneewongvatana1999s}.


Then a MapReduce job is launched to map all the points to m slave machines and collect statistics of each object. Before the Map phase is launched, the frontier information is loaded to memory from DFS in each mapper. The mapper reads instances, justifies what split the instance is belonged to, assigns one split key for the instance.

In addition, the map phase aggregates statistics of every object. An in-memory table is created and maintained for statistics. It can be implemented by well-known distributed shared memory~\cite{DSM} easily. Assume $|O|$ is the number of objects. The table collects the object ID, the minimum coordinates, the maximum coordinates. It is easily collected since mappers read all instances, and is able to obtain the maximum and minimum value by only comparing its current coordinate with the value in the table.
The maximum and minimum coordinates of every object benefit query process by pruning some objects that don't need to be considered.

\subsection{Reduce Phase}
After map phase, all instances are mapped to designated reducers, and ready to perform probabilistic skyline. The Reduce Phase is launched with constructing uncompleted k-d tree from the current root, which is the rectangle bounded by its frontiers passed. The kd-tree construction continues until each leaf corresponds to one point.

For any node rather than leaf, represents a hyper-rectangle bounded for its children, all of which are within the rectangle. For a node $R$, in the following Skyline computation, instances other than those in R are looked up to find the domination relationship with $R$. For an instance \(p\) outside $R$, there exist three scenarios of relationships: $R$ is dominated by $p$ (all instances in $R$ are dominated by $p$); some area of $R$ is dominated by some instance (The domination area of $R$ intersects one of $p$); some instance is fully dominated by R (All instances in $R$ dominate $p$).

After the tree is constructed, we pre-order traversal
